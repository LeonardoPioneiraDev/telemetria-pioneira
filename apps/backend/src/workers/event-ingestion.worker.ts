BigInt.prototype.toJSON = function () {
  return this.toString();
};

import { AppDataSource } from '@/data-source.js';
import { EtlControl } from '@/entities/etl-control.entity.js';
import { TelemetryEvent } from '@/entities/telemetry-event.entity.js';
import { DriverRepository } from '@/repositories/driver.repository.js';
import { EtlControlRepository } from '@/repositories/etl-control.repository.js';
import { EventTypeRepository } from '@/repositories/event-type.repository.js';
import { TelemetryEventRepository } from '@/repositories/telemetry-event.repository.js';
import { VehicleRepository } from '@/repositories/vehicle.repository.js';
import { MixApiClient, MixEvent } from '@/services/mix-api-client.service.js';
import { logger } from '@/shared/utils/logger.js';
import { delay, Queue } from 'bullmq';
import { DeepPartial } from 'typeorm';

const PROCESS_NAME = 'event_ingestion';

export class EventIngestionWorker {
  private mixApiClient: MixApiClient;
  private etlControlRepository: EtlControlRepository;
  private telemetryEventRepository: TelemetryEventRepository;
  private driverRepository: DriverRepository;
  private vehicleRepository: VehicleRepository;
  private eventTypeRepository: EventTypeRepository;
  private masterDataQueue: Queue;

  constructor(
    // Inje√ß√£o de depend√™ncia para mantermos o c√≥digo test√°vel
    mixApiClient: MixApiClient,
    etlControlRepository: EtlControlRepository,
    telemetryEventRepository: TelemetryEventRepository,
    driverRepository: DriverRepository,
    vehicleRepository: VehicleRepository,
    eventTypeRepository: EventTypeRepository,
    masterDataQueue: Queue
  ) {
    this.mixApiClient = mixApiClient;
    this.etlControlRepository = etlControlRepository;
    this.telemetryEventRepository = telemetryEventRepository;
    this.driverRepository = driverRepository;
    this.vehicleRepository = vehicleRepository;
    this.eventTypeRepository = eventTypeRepository;
    this.masterDataQueue = masterDataQueue;
  }

  // async run(): Promise<void> {
  //   logger.info('üöÄ Iniciando worker de ingest√£o de eventos...');
  //   try {
  //     const control = await this.etlControlRepository.findByProcessName(PROCESS_NAME);
  //     let currentToken = control?.last_successful_sincetoken || 'NEW';
  //     let hasMoreItems = true;

  //     logger.info(`Iniciando busca de eventos com o token: ${currentToken}`);

  //     do {
  //       const response = await this.mixApiClient.getEventsSince(currentToken);

  //       if (!response) {
  //         // Se a API falhar em responder, paramos para evitar problemas.
  //         logger.error('N√£o foi poss√≠vel obter resposta da API MiX. Abortando ciclo atual.');
  //         hasMoreItems = false;
  //         continue; // Pula para a pr√≥xima itera√ß√£o (que sair√° do loop)
  //       }

  //       if (response.events.length > 0) {
  //         logger.info(`Recebidos ${response.events.length} eventos. Processando...`);
  //         await this._processEventsBatch(response.events);
  //       } else {
  //         logger.info('Nenhum evento novo encontrado nesta p√°gina.');
  //       }

  //       // Salvamos o progresso (o pr√≥ximo token) no banco de dados a cada itera√ß√£o.
  //       await this.etlControlRepository.updateToken(PROCESS_NAME, response.nextSinceToken);
  //       logger.debug(`Token de controle atualizado no banco para: ${response.nextSinceToken}`);

  //       currentToken = response.nextSinceToken;
  //       hasMoreItems = response.hasMoreItems;

  //       if (hasMoreItems) {
  //         logger.debug('Mais p√°ginas para buscar, aguardando...');
  //         await delay(5100);
  //       }
  //     } while (hasMoreItems);

  //     logger.info('‚úÖ Worker de ingest√£o de eventos concluiu com sucesso (sem mais p√°ginas).');
  //   } catch (error) {
  //     logger.error('‚ùå Erro durante a execu√ß√£o do worker de ingest√£o de eventos.', error);
  //     throw error;
  //   }
  // }

  // /**
  //  * Processa um lote de eventos recebidos da API.
  //  */
  // private async _processEventsBatch(events: MixEvent[]): Promise<void> {
  //   const uniqueEventsMap = new Map<string, MixEvent>();
  //   for (const event of events) {
  //     uniqueEventsMap.set(event.EventId, event);
  //   }
  //   const uniqueEvents = Array.from(uniqueEventsMap.values());

  //   if (events.length !== uniqueEvents.length) {
  //     logger.warn(
  //       `Lote de eventos continha duplicatas internas. Recebidos: ${events.length}, √∫nicos: ${uniqueEvents.length}`
  //     );
  //   }

  //   const incomingExternalIds = uniqueEvents.map(event => BigInt(event.EventId));

  //   if (incomingExternalIds.length === 0) {
  //     logger.info('Nenhum evento v√°lido para processar ap√≥s a de-duplica√ß√£o.');
  //     return;
  //   }

  //   const existingExternalIds =
  //     await this.telemetryEventRepository.findExistingExternalIds(incomingExternalIds);
  //   const existingIdsSet = new Set(existingExternalIds);
  //   const newEvents = uniqueEvents.filter(event => !existingIdsSet.has(BigInt(event.EventId)));

  //   if (newEvents.length === 0) {
  //     logger.info('Todos os eventos recebidos j√° existem no banco. Nada a ser inserido.');
  //     return;
  //   }
  //   logger.info(
  //     `Filtragem de duplicatas: ${uniqueEvents.length} √∫nicos recebidos, ${newEvents.length} s√£o novos.`
  //   );

  //   // Etapa 2: Mapear e salvar
  //   const eventsToCreate: DeepPartial<TelemetryEvent>[] = newEvents.map(event => {
  //     return {
  //       external_id: BigInt(event.EventId),
  //       event_timestamp: event.StartDateTime,
  //       latitude: event.StartPosition?.Latitude,
  //       longitude: event.StartPosition?.Longitude,
  //       speed: event.StartPosition?.SpeedKilometresPerHour,
  //       location_description: event.StartPosition?.FormattedAddress,
  //       raw_data: event,
  //       driver_external_id: event.DriverId ? BigInt(event.DriverId) : null,
  //       vehicle_external_id: event.AssetId ? BigInt(event.AssetId) : null,
  //       event_type_external_id: event.EventTypeId ? BigInt(event.EventTypeId) : null,
  //     };
  //   });

  //   if (eventsToCreate.length > 0) {
  //     await this.telemetryEventRepository.bulkCreate(eventsToCreate);
  //     logger.info(`‚úÖ ${eventsToCreate.length} novos eventos foram salvos no banco.`);
  //     this.triggerMasterDataSyncForMissing(newEvents);
  //   }
  // }

  async run(): Promise<void> {
    logger.info('üöÄ Iniciando worker de ingest√£o de eventos...');
    try {
      const control = await this.etlControlRepository.findByProcessName(PROCESS_NAME);
      let currentToken = control?.last_successful_sincetoken || 'NEW';
      let hasMoreItems = true;

      logger.info(`Iniciando busca de eventos com o token: ${currentToken}`);

      do {
        const response = await this.mixApiClient.getEventsSince(currentToken);
        if (!response) {
          logger.error('N√£o foi poss√≠vel obter resposta da API MiX. Abortando ciclo atual.');
          hasMoreItems = false;
          continue;
        }

        // O _processEventsBatch agora s√≥ filtra e retorna os eventos a serem criados
        const eventsToCreate = this._processEventsBatch(response.events);

        // A l√≥gica de salvar e atualizar o token agora √© at√¥mica
        await AppDataSource.transaction(async transactionalEntityManager => {
          if (eventsToCreate.length > 0) {
            await transactionalEntityManager
              .getRepository(TelemetryEvent)
              .save(eventsToCreate, { chunk: 200 });
            logger.info(`‚úÖ ${eventsToCreate.length} novos eventos salvos no banco.`);

            this.triggerMasterDataSyncForMissing(eventsToCreate.map(e => e.raw_data as MixEvent));
          }

          // Atualizamos o token DENTRO da mesma transa√ß√£o
          const controlRepo = transactionalEntityManager.getRepository(EtlControl);
          await controlRepo.update(
            { process_name: PROCESS_NAME },
            { last_successful_sincetoken: response.nextSinceToken }
          );
        });

        logger.debug(`Token de controle atualizado no banco para: ${response.nextSinceToken}`);

        currentToken = response.nextSinceToken;
        hasMoreItems = response.hasMoreItems;

        if (hasMoreItems) {
          logger.debug('Mais p√°ginas para buscar, aguardando...');
          await delay(5100);
        }
      } while (hasMoreItems);

      logger.info('‚úÖ Worker de ingest√£o de eventos concluiu com sucesso (sem mais p√°ginas).');
    } catch (error) {
      logger.error('‚ùå Erro durante a execu√ß√£o do worker de ingest√£o de eventos.', error);
      throw error;
    }
  }

  /**
   * ESTE M√âTODO AGORA √â S√çNCRONO E PURO.
   * Ele apenas recebe uma lista de eventos, remove duplicatas e retorna
   * a lista pronta para ser salva, sem I/O.
   */
  private _processEventsBatch(events: MixEvent[]): DeepPartial<TelemetryEvent>[] {
    const uniqueEventsMap = new Map<string, MixEvent>();
    for (const event of events) {
      uniqueEventsMap.set(event.EventId, event);
    }
    const uniqueEvents = Array.from(uniqueEventsMap.values());

    if (events.length !== uniqueEvents.length) {
      logger.warn(
        `Lote de eventos continha duplicatas internas. Recebidos: ${events.length}, √∫nicos: ${uniqueEvents.length}`
      );
    }

    // NOTA: A verifica√ß√£o contra o banco foi removida daqui.
    // A transa√ß√£o garante que, se o job for re-executado, ele tentar√°
    // inserir o mesmo lote e falhar√° na constraint de chave √∫nica,
    // causando um rollback e mantendo o estado consistente. O job falhar√°,
    // o que √© o comportamento correto, evitando dados duplicados.
    // Para um sistema mais avan√ßado, poder√≠amos manter a verifica√ß√£o, mas
    // a transa√ß√£o j√° nos d√° a garantia de seguran√ßa principal.

    return uniqueEvents.map(event => ({
      external_id: BigInt(event.EventId),
      event_timestamp: event.StartDateTime,
      latitude: event.StartPosition?.Latitude,
      longitude: event.StartPosition?.Longitude,
      speed: event.StartPosition?.SpeedKilometresPerHour,
      location_description: event.StartPosition?.FormattedAddress,
      raw_data: event,
      driver_external_id: event.DriverId ? BigInt(event.DriverId) : null,
      vehicle_external_id: event.AssetId ? BigInt(event.AssetId) : null,
      event_type_external_id: event.EventTypeId ? BigInt(event.EventTypeId) : null,
    }));
  }

  /**
   * Verifica quais dados mestres (ve√≠culo, motorista, etc.) n√£o existem
   * no banco e dispara um job para o worker de sincroniza√ß√£o.
   */
  private async triggerMasterDataSyncForMissing(newEvents: MixEvent[]): Promise<void> {
    try {
      // 1. Coletar todos os IDs externos √∫nicos do lote
      const vehicleIds = [...new Set(newEvents.map(e => e.AssetId).filter(Boolean))];
      const driverIds = [...new Set(newEvents.map(e => e.DriverId).filter(Boolean))];
      const eventTypeIds = [...new Set(newEvents.map(e => e.EventTypeId).filter(Boolean))];

      // 2. Buscar no banco quais desses IDs j√° existem
      const [existingVehicles, existingDrivers, existingEventTypes] = await Promise.all([
        this.vehicleRepository.findByExternalIds(vehicleIds),
        this.driverRepository.findByExternalIds(driverIds),
        this.eventTypeRepository.findByExternalIds(eventTypeIds),
      ]);

      const existingVehicleIds = new Set(existingVehicles.map(v => v.external_id));
      const existingDriverIds = new Set(existingDrivers.map(d => d.external_id));
      const existingEventTypeIds = new Set(existingEventTypes.map(e => e.external_id));

      // 3. Identificar se h√° algum ID faltando
      const hasMissingVehicles = vehicleIds.some(id => !existingVehicleIds.has(id));
      const hasMissingDrivers = driverIds.some(id => !existingDriverIds.has(id));
      const hasMissingEventTypes = eventTypeIds.some(id => !existingEventTypeIds.has(id));

      if (hasMissingVehicles || hasMissingDrivers || hasMissingEventTypes) {
        logger.info('IDs de dados mestres n√£o encontrados. Disparando job de sincroniza√ß√£o...');

        // 4. Disparar um √∫nico job para o worker 'master-data-sync'
        // Usamos um ID de job fixo para evitar duplicatas em um curto espa√ßo de tempo
        await this.masterDataQueue.add(
          'sync-all-master-data',
          {},
          {
            jobId: 'sync-on-demand',
            removeOnComplete: true, // Limpa o job da fila ap√≥s o sucesso
            removeOnFail: true,
          }
        );
      }
    } catch (error) {
      logger.error('Falha ao disparar o job de sincroniza√ß√£o de dados mestres.', error);
    }
  }
}
